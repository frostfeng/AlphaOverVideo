//
//  AlphaOverVideo.metal
//
//  See license.txt for license terms.
//
//  This module contains Metal shader source code.

#include <metal_stdlib>
#include <simd/simd.h>

using namespace metal;

// Include header shared between this Metal shader code and C code executing Metal API commands
#import "AlphaOverVideoShaderTypes.h"

// Vertex shader outputs and per-fragment inputs. Includes clip-space position and vertex outputs
//  interpolated by rasterizer and fed to each fragment generated by clip-space primitives.
typedef struct
{
    // The [[position]] attribute qualifier of this member indicates this value is the clip space
    //   position of the vertex wen this structure is returned from the vertex shader
    float4 clipSpacePosition [[position]];

    // Since this member does not have a special attribute qualifier, the rasterizer will
    //   interpolate its value with values of other vertices making up the triangle and
    //   pass that interpolated value to the fragment shader for each fragment in that triangle;
    float2 textureCoordinate;

} RasterizerData;

// Vertex Function that renders full screen flipped texture

vertex RasterizerData
identityVertexShader(uint vertexID [[ vertex_id ]],
             constant AAPLVertex *vertexArray [[ buffer(0) ]])
{
  RasterizerData out;
  
  // Index into our array of positions to get the current vertex
  //   Our positons are specified in pixel dimensions (i.e. a value of 100 is 100 pixels from
  //   the origin)
  float2 pixelSpacePosition = vertexArray[vertexID].position.xy;
  
  // THe output position of every vertex shader is in clip space (also known as normalized device
  //   coordinate space, or NDC).   A value of (-1.0, -1.0) in clip-space represents the
  //   lower-left corner of the viewport wheras (1.0, 1.0) represents the upper-right corner of
  //   the viewport.
  
  out.clipSpacePosition.xy = pixelSpacePosition;
  
  // Set the z component of our clip space position 0 (since we're only rendering in
  //   2-Dimensions for this sample)
  out.clipSpacePosition.z = 0.0;
  
  // Set the w component to 1.0 since we don't need a perspective divide, which is also not
  //   necessary when rendering in 2-Dimensions
  out.clipSpacePosition.w = 1.0;
  
  // Pass our input textureCoordinate straight to our output RasterizerData.  This value will be
  //   interpolated with the other textureCoordinate values in the vertices that make up the
  //   triangle.
  out.textureCoordinate = vertexArray[vertexID].textureCoordinate;
  out.textureCoordinate.y = 1.0 - out.textureCoordinate.y;
  
  return out;
}


// Fragment shader that can do simple rescale, note that the input
// and output is float here as opposed to half to support 16 bit
// float input texture.

fragment float4
samplingShader(RasterizerData in [[stage_in]],
               texture2d<float, access::sample> colorTexture [[ texture(AAPLTextureIndexBaseColor) ]])
{
  constexpr sampler textureSampler (mag_filter::linear,
                                    min_filter::linear);
  
  // Sample the texture to obtain a color
  const float4 colorSample = colorTexture.sample(textureSampler, in.textureCoordinate);
  
  // We return the color of the texture
  return colorSample;
}

// BT.709 rendering fragment shader

// FIXME: note that Metal "fast math" option would automatically
// replace pow() with exp2(y * log2(x)). This may or may not matter,
// an actual 2x performance improvement can be enabled by simply
// doing 1 render pass instead of 2 when rendering at exact pixel size.

//static inline
//float BT709_nonLinearNormToLinear(float normV) {
//  
//  if (normV < 0.081f) {
//    normV *= (1.0f / 4.5f);
//  } else {
//    const float a = 0.099f;
//    const float gamma = 1.0f / 0.45f; // 2.2
//    normV = (normV + a) * (1.0f / (1.0f + a));
//    normV = pow(normV, gamma);
//  }
//  
//  return normV;
//}

#define APPLE_GAMMA_196 (1.960938f)

static inline
float Apple196_nonLinearNormToLinear(float normV) {
  const float xIntercept = 0.05583828f;
  
  if (normV < xIntercept) {
    normV *= (1.0f / 16.0f);
  } else {
    const float gamma = APPLE_GAMMA_196;
    normV = pow(normV, gamma);
  }
  
  return normV;
}

// Convert a non-linear log value to a linear value.
// Note that normV must be normalized in the range [0.0 1.0].

static inline
float sRGB_nonLinearNormToLinear(float normV)
{
  if (normV <= 0.04045f) {
    normV *= (1.0f / 12.92f);
  } else {
    const float a = 0.055f;
    const float gamma = 2.4f;
    //const float gamma = 1.0f / (1.0f / 2.4f);
    normV = (normV + a) * (1.0f / (1.0f + a));
    normV = pow(normV, gamma);
  }
  
  return normV;
}

// Unused since this does not decode video colors to linear light

//static inline
//float4 BT709_gamma_decode(const float4 rgba) {
//  rgba.r = BT709_nonLinearNormToLinear(rgba.r);
//  rgba.g = BT709_nonLinearNormToLinear(rgba.g);
//  rgba.b = BT709_nonLinearNormToLinear(rgba.b);
//  return rgba;
//}

static inline
float4 sRGB_gamma_decode(const float4 rgba) {
  rgba.r = sRGB_nonLinearNormToLinear(rgba.r);
  rgba.g = sRGB_nonLinearNormToLinear(rgba.g);
  rgba.b = sRGB_nonLinearNormToLinear(rgba.b);
  return rgba;
}

// Note that the Apple gamma 1.961 decoding logic
// is used when a BT709 flag is detected for an
// input pixel buffer. The original BT709 gamma
// functions does not actually convert video
// graded color values to linear identity

static inline
float4 Apple196_gamma_decode(const float4 rgba) {
  rgba.r = Apple196_nonLinearNormToLinear(rgba.r);
  rgba.g = Apple196_nonLinearNormToLinear(rgba.g);
  rgba.b = Apple196_nonLinearNormToLinear(rgba.b);
  return rgba;
}

// Extract common BT.709 decode logic from the 2 implementations,
// this method accepts (Y Cb Cr) and returns gamma encoded
// values if the original data was gamma encoded.

static inline
float4 BT709_decode(const float Y, const float Cb, const float Cr) {
  // Y already normalized to range [0 255]
  //
  // Note that the matrix multiply will adjust
  // this byte normalized range to account for
  // the limited range [16 235]
  //
  // Note that while a half float can be read from
  // the input textures, the values need to be full float
  // from this point forward since the bias values
  // need to be precise to avoid togggling blue and green
  // values depending on rounding.
  
  float Yn = (Y - (16.0f/255.0f));
  
  // Normalize Cb and CR with zero at 128 and range [0 255]
  // Note that matrix will adjust to limited range [16 240]
  
  float Cbn = (Cb - (128.0f/255.0f));
  float Crn = (Cr - (128.0f/255.0f));
  
  // Zero out the UV colors
  //Cbn = 0.0h;
  //Crn = 0.0h;
  
  // Represent half values as full precision float
  float3 YCbCr = float3(Yn, Cbn, Crn);
  
  // BT.709 (HDTV)
  // (col0) (col1) (col2)
  //
  // 1.1644  0.0000  1.7927
  // 1.1644 -0.2132 -0.5329
  // 1.1644  2.1124  0.0000
  
  // precise to 4 decimal places
  
  const float3x3 kColorConversion709 = float3x3(
                                                // column 0
                                                float3(1.1644f, 1.1644f, 1.1644f),
                                                // column 1
                                                float3(0.0f, -0.2132f, 2.1124f),
                                                // column 2
                                                float3(1.7927f, -0.5329f, 0.0f));
  
  // matrix to vector mult
  float3 rgb = kColorConversion709 * YCbCr;
  
  //  float Rn = (Yn * BT709Mat[0]) + (Cbn * BT709Mat[1]) + (Crn * BT709Mat[2]);
  //  float Gn = (Yn * BT709Mat[3]) + (Cbn * BT709Mat[4]) + (Crn * BT709Mat[5]);
  //  float Bn = (Yn * BT709Mat[6]) + (Cbn * BT709Mat[7]) + (Crn * BT709Mat[8]);
  
  //  float3 rgb;
  //  rgb.r = (YCbCr[0] * kColorConversion709[0][0]) + (YCbCr[1] * kColorConversion709[1][0]) + (YCbCr[2] * kColorConversion709[2][0]);
  //  rgb.g = (YCbCr[0] * kColorConversion709[0][1]) + (YCbCr[1] * kColorConversion709[1][1]) + (YCbCr[2] * kColorConversion709[2][1]);
  //  rgb.b = (YCbCr[0] * kColorConversion709[0][2]) + (YCbCr[1] * kColorConversion709[1][2]) + (YCbCr[2] * kColorConversion709[2][2]);
  
  rgb = saturate(rgb);
  
  // Note that gamma decoding seems to have very little impact
  // on performance since the entire shader is IO bound.
  
  return float4(rgb.r, rgb.g, rgb.b, 1.0f);
}

// Decode the Y portion of a BT.709 input value knowing
// that Cb and Cr are both zero.

static inline
float BT709_decodeAlpha(const float Y) {
  // Y already normalized to range [0 255]
  //
  // Note that the matrix multiply will adjust
  // this byte normalized range to account for
  // the limited range [16 235]
  //
  // Note that while a half float can be read from
  // the input textures, the values need to be full float
  // from this point forward since the bias values
  // need to be precise to avoid togggling blue and green
  // values depending on rounding.
  
  float Yn = (Y - (16.0f/255.0f));
  
  float YMult = 1.1644f;
  
  Yn = Yn * YMult;
  Yn = saturate(Yn);
  
  return Yn;
}

// Decode with Apple 196 gamma

fragment float4
BT709ToLinearSRGBFragment(RasterizerData in [[stage_in]],
                          texture2d<half, access::sample>  inYTexture  [[texture(AAPLTextureIndexYPlane)]],
                          texture2d<half, access::sample>  inUVTexture [[texture(AAPLTextureIndexCbCrPlane)]]
                          )
{
  constexpr sampler textureSampler (mag_filter::nearest, min_filter::nearest);
  
  float Y = float(inYTexture.sample(textureSampler, in.textureCoordinate).r);
  half2 uvSamples = inUVTexture.sample(textureSampler, in.textureCoordinate).rg;
  
  float Cb = float(uvSamples[0]);
  float Cr = float(uvSamples[1]);
  
  float4 pixel = BT709_decode(Y, Cb, Cr);
  return Apple196_gamma_decode(pixel);
}

// Decode with sRGB gamma

fragment float4
sRGBToLinearSRGBFragment(RasterizerData in [[stage_in]],
                          texture2d<half, access::sample>  inYTexture  [[texture(AAPLTextureIndexYPlane)]],
                          texture2d<half, access::sample>  inUVTexture [[texture(AAPLTextureIndexCbCrPlane)]]
                          )
{
  constexpr sampler textureSampler (mag_filter::nearest, min_filter::nearest);
  
  float Y = float(inYTexture.sample(textureSampler, in.textureCoordinate).r);
  half2 uvSamples = inUVTexture.sample(textureSampler, in.textureCoordinate).rg;
  
  float Cb = float(uvSamples[0]);
  float Cr = float(uvSamples[1]);
  
  float4 pixel = BT709_decode(Y, Cb, Cr);
  return sRGB_gamma_decode(pixel);
}

// Decode without a gamma adjustment, original input is linear
// and output will also be linear.

fragment float4
LinearToLinearSRGBFragment(RasterizerData in [[stage_in]],
                         texture2d<half, access::sample>  inYTexture  [[texture(AAPLTextureIndexYPlane)]],
                         texture2d<half, access::sample>  inUVTexture [[texture(AAPLTextureIndexCbCrPlane)]]
                         )
{
  constexpr sampler textureSampler (mag_filter::nearest, min_filter::nearest);
  
  float Y = float(inYTexture.sample(textureSampler, in.textureCoordinate).r);
  half2 uvSamples = inUVTexture.sample(textureSampler, in.textureCoordinate).rg;
  
  float Cb = float(uvSamples[0]);
  float Cr = float(uvSamples[1]);
  
  float4 pixel = BT709_decode(Y, Cb, Cr);
  return pixel;
}

// Decode with compute kernel and Apple 196 gamma function

kernel void
BT709ToLinearSRGBKernel(texture2d<half, access::read>  inYTexture  [[texture(0)]],
                        texture2d<half, access::read>  inUVTexture [[texture(1)]],
                        texture2d<float, access::write> outTexture  [[texture(2)]],
                        ushort2                         gid         [[thread_position_in_grid]])
{
  // Check if the pixel is within the bounds of the output texture
  if((gid.x >= outTexture.get_width()) || (gid.y >= outTexture.get_height()))
  {
    // Return early if the pixel is out of bounds
    return;
  }
  
  float Y = float(inYTexture.read(gid).r);
  half2 uvSamples = inUVTexture.read(gid/2).rg;
  float Cb = float(uvSamples[0]);
  float Cr = float(uvSamples[1]);
  
  float4 pixel = BT709_decode(Y, Cb, Cr);
  pixel = Apple196_gamma_decode(pixel);
  outTexture.write(pixel, gid);
}

// Decode with compute kernel and sRGB gamma function

kernel void
sRGBToLinearSRGBKernel(texture2d<half, access::read>  inYTexture  [[texture(0)]],
                        texture2d<half, access::read>  inUVTexture [[texture(1)]],
                        texture2d<float, access::write> outTexture  [[texture(2)]],
                        ushort2                         gid         [[thread_position_in_grid]])
{
  // Check if the pixel is within the bounds of the output texture
  if((gid.x >= outTexture.get_width()) || (gid.y >= outTexture.get_height()))
  {
    // Return early if the pixel is out of bounds
    return;
  }
  
  float Y = float(inYTexture.read(gid).r);
  half2 uvSamples = inUVTexture.read(gid/2).rg;
  float Cb = float(uvSamples[0]);
  float Cr = float(uvSamples[1]);
  
  float4 pixel = BT709_decode(Y, Cb, Cr);
  pixel = sRGB_gamma_decode(pixel);
  outTexture.write(pixel, gid);
}

// Decode without a gamma adjustment, original input is linear
// and output will also be linear.

kernel void
LinearToLinearSRGBKernel(texture2d<half, access::read>  inYTexture  [[texture(0)]],
                       texture2d<half, access::read>  inUVTexture [[texture(1)]],
                       texture2d<float, access::write> outTexture  [[texture(2)]],
                       ushort2                         gid         [[thread_position_in_grid]])
{
  // Check if the pixel is within the bounds of the output texture
  if((gid.x >= outTexture.get_width()) || (gid.y >= outTexture.get_height()))
  {
    // Return early if the pixel is out of bounds
    return;
  }
  
  float Y = float(inYTexture.read(gid).r);
  half2 uvSamples = inUVTexture.read(gid/2).rg;
  float Cb = float(uvSamples[0]);
  float Cr = float(uvSamples[1]);
  
  float4 pixel = BT709_decode(Y, Cb, Cr);
  outTexture.write(pixel, gid);
}

// Decode with sRGB gamma and an alpha channel

fragment float4
sRGBToLinearSRGBFragmentAlpha(RasterizerData in [[stage_in]],
                              texture2d<half, access::sample>  inYTexture  [[texture(AAPLTextureIndexYPlane)]],
                              texture2d<half, access::sample>  inUVTexture [[texture(AAPLTextureIndexCbCrPlane)]],
                              texture2d<half, access::sample>  inATexture  [[texture(AAPLTextureIndexAlphaPlane)]]
                              )
{
  constexpr sampler textureSampler (mag_filter::nearest, min_filter::nearest);
  
  float Y = float(inYTexture.sample(textureSampler, in.textureCoordinate).r);
  half2 uvSamples = inUVTexture.sample(textureSampler, in.textureCoordinate).rg;
  
  float Cb = float(uvSamples[0]);
  float Cr = float(uvSamples[1]);
  
  float4 pixel = BT709_decode(Y, Cb, Cr);
  pixel = sRGB_gamma_decode(pixel);
  
  // Load alpha value from alpha texture
  float A = float(inATexture.sample(textureSampler, in.textureCoordinate).r);
  A = BT709_decodeAlpha(A);
  // Premultiply
//  pixel.r *= A;
//  pixel.g *= A;
//  pixel.b *= A;
  pixel.a = A;
  return pixel;
}
